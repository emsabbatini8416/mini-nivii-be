# ğŸš€ Nivii Challenge Backend

Scalable API that c## ğŸ—ï¸ Scalable Architecture

âœ… **Redis Cache** - Distributed cache for fast responses  
âœ… **Streaming CSV** - Efficient loading without full `pd.read_csv()`  
âœ… **Multi-Worker** - 4 concurrent Gunicorn workers  
âœ… **Health Checks** - Automatic service monitoring  
âœ… **Connection Pooling** - Optimized DB connection management  

## ğŸ“Š Tech Stack

- **FastAPI** + **Uvicorn** - High-performance async API
- **OpenAI GPT** - Natural language â†’ SQL conversion  
- **Redis** - Scalable distributed cache
- **SQLAlchemy** - ORM with connection pooling
- **SQLite** - Database with 24K+ records
- **Docker** - Multi-stage containerizationl language** into SQL queries on sales data using **OpenAI** + **FastAPI**.

## ğŸ”¥ Quick Start

### 1. Launch with Docker Compose
```bash
# Clone and enter directory
git clone <repo-url>
cd nivii-challenge-be

# Configure environment variables
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY

# Launch entire stack
docker-compose up --build
```

### 2. Test the API
- **Swagger UI**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health
- **Statistics**: http://localhost:8000/stats

## ğŸ¯ Main Endpoints

| Endpoint | Method | Description |
|----------|---------|-------------|
| `/docs` | GET | **Interactive Swagger UI** |
| `/health` | GET | System health check |
| `/stats` | GET | Data statistics |
| `/query` | POST | Direct SQL query |
| `/natural-query` | POST | **Natural language question** |

## ğŸ’¬ Usage Example

```bash
# Natural language question
curl -X POST "http://localhost:8000/natural-query" \
  -H "Content-Type: application/json" \
  -d '{"question": "What are the top 5 best-selling products?"}'

# Direct SQL query  
curl -X POST "http://localhost:8000/query" \
  -H "Content-Type: application/json" \
  -d '{"sql": "SELECT COUNT(*) FROM sales"}'
```

## ğŸ—ï¸ Arquitectura Escalable

âœ… **Redis Cache** - Cache distribuido para respuestas rÃ¡pidas  
âœ… **Streaming CSV** - Carga eficiente sin `pd.read_csv()` completo  
âœ… **Multi-Worker** - 4 workers Gunicorn concurrentes  
âœ… **Health Checks** - Monitoreo automÃ¡tico de servicios  
âœ… **Connection Pooling** - GestiÃ³n optimizada de conexiones DB  

## ï¿½ Stack TecnolÃ³gico

- **FastAPI** + **Uvicorn** - API async de alto rendimiento
- **OpenAI GPT** - ConversiÃ³n lenguaje natural â†’ SQL  
- **Redis** - Cache distribuido escalable
- **SQLAlchemy** - ORM con connection pooling
- **SQLite** - Base de datos con 24K+ registros
- **Docker** - ContenedorizaciÃ³n multi-stage

## ğŸ“Š Data

**24,212 sales records** with columns:
- `date`, `week_day`, `hour` - Temporal information
- `ticket_number`, `waiter` - Identifiers
- `product_name`, `quantity`, `unitary_price`, `total` - Sales data

## ğŸ”§ Local Development

```bash
# View logs in real time
docker-compose logs -f backend

# Stop services
docker-compose down

# Clean volumes (reset data)
docker-compose down --volumes
```

## ğŸ“„ License

MIT License
